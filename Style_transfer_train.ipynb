{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "id": "AGnMfY3HDdhz",
    "outputId": "1abd6b28-8cce-4f7a-ba04-1d592db20858"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorboardX\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/f1/5843425495765c8c2dd0784a851a93ef204d314fc87bcc2bbb9f662a3ad1/tensorboardX-2.0-py2.py3-none-any.whl (195kB)\n",
      "\u001b[K     |████████████████████████████████| 204kB 1.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/ksobolev/opt/anaconda3/lib/python3.7/site-packages (from tensorboardX) (1.17.2)\n",
      "Requirement already satisfied: six in /Users/ksobolev/opt/anaconda3/lib/python3.7/site-packages (from tensorboardX) (1.12.0)\n",
      "Collecting protobuf>=3.8.0 (from tensorboardX)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/25/c057a298635d08d087a20f51ff4287d821814208ebb045d84ea65535b3e3/protobuf-3.11.3-cp37-cp37m-macosx_10_9_x86_64.whl (1.3MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3MB 3.4MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /Users/ksobolev/opt/anaconda3/lib/python3.7/site-packages (from protobuf>=3.8.0->tensorboardX) (41.4.0)\n",
      "Installing collected packages: protobuf, tensorboardX\n",
      "Successfully installed protobuf-3.11.3 tensorboardX-2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7Ay5SBnBCAll"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "from PIL import Image, ImageFile\n",
    "from tensorboardX import SummaryWriter\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "cudnn.benchmark = True\n",
    "Image.MAX_IMAGE_PIXELS = None  # Disable DecompressionBombError\n",
    "# Disable OSError: image file is truncated\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "UgCIKqfKIXUH",
    "outputId": "94093910-7ba8-4086-86ef-1a2926d4979b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vV-fZe_XIgOZ",
    "outputId": "d934f98c-82a6-47ca-98a6-c0cc989fd67a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg_normalised.pth\n"
     ]
    }
   ],
   "source": [
    "!ls drive/'My Drive'/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h93j09IrD809"
   },
   "outputs": [],
   "source": [
    "content_dir = \"/content\"\n",
    "style_dir = \"/style\"\n",
    "vgg_path = \"./models/vgg_normalised.pth\"\n",
    "save_dir = '/content/experiments'\n",
    "log_dir = './logs'\n",
    "lr = 1e-4\n",
    "lr_decay = 5e-5\n",
    "max_iter = 160000\n",
    "batch_size = 8\n",
    "style_weight = 10.0\n",
    "content_weight = 1.0\n",
    "n_threads = 1\n",
    "save_model_interval = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e4SEEE0zDb8G"
   },
   "outputs": [],
   "source": [
    "def train_transform():\n",
    "    transform_list = [\n",
    "        transforms.Resize(size=(512, 512)),\n",
    "        transforms.RandomCrop(256),\n",
    "        transforms.ToTensor()\n",
    "    ]\n",
    "    return transforms.Compose(transform_list)\n",
    "\n",
    "\n",
    "class FlatFolderDataset(data.Dataset):\n",
    "    def __init__(self, root, transform):\n",
    "        super(FlatFolderDataset, self).__init__()\n",
    "        self.root = root\n",
    "        self.paths = list(Path(self.root).glob('*'))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path = self.paths[index]\n",
    "        img = Image.open(str(path)).convert('RGB')\n",
    "        img = self.transform(img)\n",
    "        return img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def name(self):\n",
    "        return 'FlatFolderDataset'\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, iteration_count):\n",
    "    \"\"\"Imitating the original implementation\"\"\"\n",
    "    lr = args.lr / (1.0 + args.lr_decay * iteration_count)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FBf9BOh5GmdQ"
   },
   "outputs": [],
   "source": [
    "def calc_mean_std(feat, eps=1e-5):\n",
    "    # eps is a small value added to the variance to avoid divide-by-zero.\n",
    "    size = feat.size()\n",
    "    assert (len(size) == 4)\n",
    "    N, C = size[:2]\n",
    "    feat_var = feat.view(N, C, -1).var(dim=2) + eps\n",
    "    feat_std = feat_var.sqrt().view(N, C, 1, 1)\n",
    "    feat_mean = feat.view(N, C, -1).mean(dim=2).view(N, C, 1, 1)\n",
    "    return feat_mean, feat_std\n",
    "\n",
    "\n",
    "def adaptive_instance_normalization(content_feat, style_feat):\n",
    "    assert (content_feat.size()[:2] == style_feat.size()[:2])\n",
    "    size = content_feat.size()\n",
    "    style_mean, style_std = calc_mean_std(style_feat)\n",
    "    content_mean, content_std = calc_mean_std(content_feat)\n",
    "\n",
    "    normalized_feat = (content_feat - content_mean.expand(\n",
    "        size)) / content_std.expand(size)\n",
    "    return normalized_feat * style_std.expand(size) + style_mean.expand(size)\n",
    "\n",
    "\n",
    "def _calc_feat_flatten_mean_std(feat):\n",
    "    # takes 3D feat (C, H, W), return mean and std of array within channels\n",
    "    assert (feat.size()[0] == 3)\n",
    "    assert (isinstance(feat, torch.FloatTensor))\n",
    "    feat_flatten = feat.view(3, -1)\n",
    "    mean = feat_flatten.mean(dim=-1, keepdim=True)\n",
    "    std = feat_flatten.std(dim=-1, keepdim=True)\n",
    "    return feat_flatten, mean, std\n",
    "\n",
    "\n",
    "def _mat_sqrt(x):\n",
    "    U, D, V = torch.svd(x)\n",
    "    return torch.mm(torch.mm(U, D.pow(0.5).diag()), V.t())\n",
    "\n",
    "\n",
    "def coral(source, target):\n",
    "    # assume both source and target are 3D array (C, H, W)\n",
    "    # Note: flatten -> f\n",
    "\n",
    "    source_f, source_f_mean, source_f_std = _calc_feat_flatten_mean_std(source)\n",
    "    source_f_norm = (source_f - source_f_mean.expand_as(\n",
    "        source_f)) / source_f_std.expand_as(source_f)\n",
    "    source_f_cov_eye = \\\n",
    "        torch.mm(source_f_norm, source_f_norm.t()) + torch.eye(3)\n",
    "\n",
    "    target_f, target_f_mean, target_f_std = _calc_feat_flatten_mean_std(target)\n",
    "    target_f_norm = (target_f - target_f_mean.expand_as(\n",
    "        target_f)) / target_f_std.expand_as(target_f)\n",
    "    target_f_cov_eye = \\\n",
    "        torch.mm(target_f_norm, target_f_norm.t()) + torch.eye(3)\n",
    "\n",
    "    source_f_norm_transfer = torch.mm(\n",
    "        _mat_sqrt(target_f_cov_eye),\n",
    "        torch.mm(torch.inverse(_mat_sqrt(source_f_cov_eye)),\n",
    "                 source_f_norm)\n",
    "    )\n",
    "\n",
    "    source_f_transfer = source_f_norm_transfer * \\\n",
    "                        target_f_std.expand_as(source_f_norm) + \\\n",
    "                        target_f_mean.expand_as(source_f_norm)\n",
    "\n",
    "    return source_f_transfer.view(source.size())\n",
    "\n",
    "decoder = nn.Sequential(\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(512, 256, (3, 3)),\n",
    "    nn.ReLU(),\n",
    "    nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(256, 256, (3, 3)),\n",
    "    nn.ReLU(),\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(256, 256, (3, 3)),\n",
    "    nn.ReLU(),\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(256, 256, (3, 3)),\n",
    "    nn.ReLU(),\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(256, 128, (3, 3)),\n",
    "    nn.ReLU(),\n",
    "    nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(128, 128, (3, 3)),\n",
    "    nn.ReLU(),\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(128, 64, (3, 3)),\n",
    "    nn.ReLU(),\n",
    "    nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(64, 64, (3, 3)),\n",
    "    nn.ReLU(),\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(64, 3, (3, 3)),\n",
    ")\n",
    "\n",
    "vgg = nn.Sequential(\n",
    "    nn.Conv2d(3, 3, (1, 1)),\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(3, 64, (3, 3)),\n",
    "    nn.ReLU(),  # relu1-1\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(64, 64, (3, 3)),\n",
    "    nn.ReLU(),  # relu1-2\n",
    "    nn.MaxPool2d((2, 2), (2, 2), (0, 0), ceil_mode=True),\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(64, 128, (3, 3)),\n",
    "    nn.ReLU(),  # relu2-1\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(128, 128, (3, 3)),\n",
    "    nn.ReLU(),  # relu2-2\n",
    "    nn.MaxPool2d((2, 2), (2, 2), (0, 0), ceil_mode=True),\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(128, 256, (3, 3)),\n",
    "    nn.ReLU(),  # relu3-1\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(256, 256, (3, 3)),\n",
    "    nn.ReLU(),  # relu3-2\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(256, 256, (3, 3)),\n",
    "    nn.ReLU(),  # relu3-3\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(256, 256, (3, 3)),\n",
    "    nn.ReLU(),  # relu3-4\n",
    "    nn.MaxPool2d((2, 2), (2, 2), (0, 0), ceil_mode=True),\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(256, 512, (3, 3)),\n",
    "    nn.ReLU(),  # relu4-1, this is the last layer used\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(512, 512, (3, 3)),\n",
    "    nn.ReLU(),  # relu4-2\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(512, 512, (3, 3)),\n",
    "    nn.ReLU(),  # relu4-3\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(512, 512, (3, 3)),\n",
    "    nn.ReLU(),  # relu4-4\n",
    "    nn.MaxPool2d((2, 2), (2, 2), (0, 0), ceil_mode=True),\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(512, 512, (3, 3)),\n",
    "    nn.ReLU(),  # relu5-1\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(512, 512, (3, 3)),\n",
    "    nn.ReLU(),  # relu5-2\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(512, 512, (3, 3)),\n",
    "    nn.ReLU(),  # relu5-3\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(512, 512, (3, 3)),\n",
    "    nn.ReLU()  # relu5-4\n",
    ")\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Net, self).__init__()\n",
    "        enc_layers = list(encoder.children())\n",
    "        self.enc_1 = nn.Sequential(*enc_layers[:4])  # input -> relu1_1\n",
    "        self.enc_2 = nn.Sequential(*enc_layers[4:11])  # relu1_1 -> relu2_1\n",
    "        self.enc_3 = nn.Sequential(*enc_layers[11:18])  # relu2_1 -> relu3_1\n",
    "        self.enc_4 = nn.Sequential(*enc_layers[18:31])  # relu3_1 -> relu4_1\n",
    "        self.decoder = decoder\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "\n",
    "        # fix the encoder\n",
    "        for name in ['enc_1', 'enc_2', 'enc_3', 'enc_4']:\n",
    "            for param in getattr(self, name).parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    # extract relu1_1, relu2_1, relu3_1, relu4_1 from input image\n",
    "    def encode_with_intermediate(self, input):\n",
    "        results = [input]\n",
    "        for i in range(4):\n",
    "            func = getattr(self, 'enc_{:d}'.format(i + 1))\n",
    "            results.append(func(results[-1]))\n",
    "        return results[1:]\n",
    "\n",
    "    # extract relu4_1 from input image\n",
    "    def encode(self, input):\n",
    "        for i in range(4):\n",
    "            input = getattr(self, 'enc_{:d}'.format(i + 1))(input)\n",
    "        return input\n",
    "\n",
    "    def calc_content_loss(self, input, target):\n",
    "        assert (input.size() == target.size())\n",
    "        assert (target.requires_grad is False)\n",
    "        return self.mse_loss(input, target)\n",
    "\n",
    "    def calc_style_loss(self, input, target):\n",
    "        assert (input.size() == target.size())\n",
    "        assert (target.requires_grad is False)\n",
    "        input_mean, input_std = calc_mean_std(input)\n",
    "        target_mean, target_std = calc_mean_std(target)\n",
    "        return self.mse_loss(input_mean, target_mean) + \\\n",
    "               self.mse_loss(input_std, target_std)\n",
    "\n",
    "    def forward(self, content, style, alpha=1.0):\n",
    "        assert 0 <= alpha <= 1\n",
    "        style_feats = self.encode_with_intermediate(style)\n",
    "        content_feat = self.encode(content)\n",
    "        t = adain(content_feat, style_feats[-1])\n",
    "        t = alpha * t + (1 - alpha) * content_feat\n",
    "\n",
    "        g_t = self.decoder(t)\n",
    "        g_t_feats = self.encode_with_intermediate(g_t)\n",
    "\n",
    "        loss_c = self.calc_content_loss(g_t_feats[-1], t)\n",
    "        loss_s = self.calc_style_loss(g_t_feats[0], style_feats[0])\n",
    "        for i in range(1, 4):\n",
    "            loss_s += self.calc_style_loss(g_t_feats[i], style_feats[i])\n",
    "        return loss_c, loss_s\n",
    "\n",
    "\n",
    "def InfiniteSampler(n):\n",
    "    # i = 0\n",
    "    i = n - 1\n",
    "    order = np.random.permutation(n)\n",
    "    while True:\n",
    "        yield order[i]\n",
    "        i += 1\n",
    "        if i >= n:\n",
    "            np.random.seed()\n",
    "            order = np.random.permutation(n)\n",
    "            i = 0\n",
    "\n",
    "\n",
    "class InfiniteSamplerWrapper(data.sampler.Sampler):\n",
    "    def __init__(self, data_source):\n",
    "        self.num_samples = len(data_source)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(InfiniteSampler(self.num_samples))\n",
    "\n",
    "    def __len__(self):\n",
    "        return 2 ** 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "htMTUHjcFit7"
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 30] Read-only file system: '/content'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/pathlib.py\u001b[0m in \u001b[0;36mmkdir\u001b[0;34m(self, mode, parents, exist_ok)\u001b[0m\n\u001b[1;32m   1257\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1258\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1259\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/experiments'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-9889d3a85581>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msave_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msave_dir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlog_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlog_dir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/pathlib.py\u001b[0m in \u001b[0;36mmkdir\u001b[0;34m(self, mode, parents, exist_ok)\u001b[0m\n\u001b[1;32m   1260\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparents\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1262\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1263\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexist_ok\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1264\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/pathlib.py\u001b[0m in \u001b[0;36mmkdir\u001b[0;34m(self, mode, parents, exist_ok)\u001b[0m\n\u001b[1;32m   1256\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1258\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1259\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1260\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparents\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 30] Read-only file system: '/content'"
     ]
    }
   ],
   "source": [
    "save_dir = Path(save_dir)\n",
    "save_dir.mkdir(exist_ok=True, parents=True)\n",
    "log_dir = Path(log_dir)\n",
    "log_dir.mkdir(exist_ok=True, parents=True)\n",
    "writer = SummaryWriter(log_dir=str(log_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388
    },
    "colab_type": "code",
    "id": "cIYtUJqhFrdk",
    "outputId": "36b78288-8855-4358-e3eb-127a85da914c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (enc_1): Sequential(\n",
       "    (0): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (2): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (enc_2): Sequential(\n",
       "    (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
       "    (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (6): ReLU()\n",
       "  )\n",
       "  (enc_3): Sequential(\n",
       "    (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
       "    (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (6): ReLU()\n",
       "  )\n",
       "  (enc_4): Sequential(\n",
       "    (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (2): ReLU()\n",
       "    (3): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (5): ReLU()\n",
       "    (6): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (7): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (8): ReLU()\n",
       "    (9): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
       "    (10): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (12): ReLU()\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (2): ReLU()\n",
       "    (3): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (6): ReLU()\n",
       "    (7): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (9): ReLU()\n",
       "    (10): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (12): ReLU()\n",
       "    (13): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (14): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (15): ReLU()\n",
       "    (16): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (17): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (18): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (19): ReLU()\n",
       "    (20): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (21): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (22): ReLU()\n",
       "    (23): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (24): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (25): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (26): ReLU()\n",
       "    (27): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (28): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1))\n",
       "  )\n",
       "  (mse_loss): MSELoss()\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = decoder\n",
    "vgg = vgg\n",
    "\n",
    "vgg.load_state_dict(torch.load(vgg_path))\n",
    "vgg = nn.Sequential(*list(vgg.children())[:31])\n",
    "network = Net(vgg, decoder)\n",
    "network.train()\n",
    "network.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "colab_type": "code",
    "id": "ofN74_stJRdc",
    "outputId": "bcab0854-57fa-426b-d03d-d60b8d7c46bc"
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-51971c4a2d49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mcontent_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0msampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mInfiniteSamplerWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     num_workers=n_threads))\n\u001b[0m\u001b[1;32m     11\u001b[0m style_iter = iter(data.DataLoader(\n\u001b[1;32m     12\u001b[0m     \u001b[0mstyle_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_SingleProcessDataLoaderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_MultiProcessingDataLoaderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    744\u001b[0m         \u001b[0;31m# prime the prefetch loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMP_STATUS_CHECK_INTERVAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_put_index\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    859\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_workers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_index\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m             \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-504923fd37c1>\u001b[0m in \u001b[0;36mInfiniteSampler\u001b[0;34m(n)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0morder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index -1 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "content_tf = train_transform()\n",
    "style_tf = train_transform()\n",
    "\n",
    "content_dataset = FlatFolderDataset(content_dir, content_tf)\n",
    "style_dataset = FlatFolderDataset(style_dir, style_tf)\n",
    "\n",
    "content_iter = iter(data.DataLoader(\n",
    "    content_dataset, batch_size=batch_size,\n",
    "    sampler=InfiniteSamplerWrapper(content_dataset),\n",
    "    num_workers=n_threads))\n",
    "style_iter = iter(data.DataLoader(\n",
    "    style_dataset, batch_size=batch_size,\n",
    "    sampler=InfiniteSamplerWrapper(style_dataset),\n",
    "    num_workers=n_threads))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zUpAh06nJucS",
    "outputId": "100d302f-c281-4a22-9fa8-29608f787b13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder.pth        vgg_normalised.pth\r\n"
     ]
    }
   ],
   "source": [
    "!ls models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9vnI-IL4KVLx",
    "outputId": "b637eb80-3b41-40f2-c08b-ef18743dcbae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.FlatFolderDataset at 0x7f0bfeaa72e8>"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fvS_TOxPKqoO"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.0'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Style_transfer_train.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
